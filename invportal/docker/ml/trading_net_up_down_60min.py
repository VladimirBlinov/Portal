# -*- coding: utf-8 -*-
"""Trading_NET_up_down_60min

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FoFpO5kFQo7_2thttFICXjOc3LhH1jpV

**Загрузка данных**
"""

!pip install finam-export

# Commented out IPython magic to ensure Python compatibility.
#Загружаем библиотеки

import pandas as pd #Пандас
import matplotlib.pyplot as plt #Отрисовка графиков
import numpy as np #Numpy
import os
import random
import time
from IPython.display import clear_output
from tqdm import tqdm

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential, Model 
from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten, Conv1D, LSTM, GlobalMaxPooling1D,MaxPooling1D, Activation, Reshape
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
import keras.backend as K
from tensorflow.keras.callbacks import LambdaCallback,ReduceLROnPlateau,EarlyStopping,ModelCheckpoint
from keras.models import load_model
from tensorflow.keras import regularizers
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.metrics import AUC, MAE
from tensorflow.keras.utils import plot_model
from tensorflow.keras.models import load_model

from sklearn import utils
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.externals import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix,roc_auc_score, roc_curve, precision_recall_fscore_support, f1_score

from scipy import stats

import logging

from finam import Exporter, Market, LookupComparator, Timeframe
from finam.utils import click_validate_enum

import seaborn as sns

# %matplotlib inline

pd.options.mode.chained_assignment = None

from google.colab import drive
drive.mount('/content/drive')

"""# Получаем входные данные"""

# Get data of stock
file_name = 'Trading_NET_v3_3'
exporter = Exporter()

def load_ticker(code):
  ticker_data = exporter.lookup(market=Market.USA, code=code,
                            name_comparator=LookupComparator.CONTAINS)
  assert len(ticker) == 1
  data_initial = exporter.download(ticker_data.index[0], market=Market.USA, timeframe=Timeframe.HOURLY)
  data = data_initial.copy()
  data = data.iloc[:,2:]
  data.reset_index(inplace=True, drop=True)
  return data

data = load_ticker('MSFT')
data

"""# Подготовка данных"""

xlen = 120  # How many candles to take in window
batch_size = 512
forward_lag = 5  # Steps forward to look
flat = 0.01  # Limit of flat moving
col = data.columns.tolist()
price_columns = col[:-1]  # Create list of price columns names
volume_column = col[-1]  # Column with volume
data

# Draw the data in channels
plt.figure(figsize=(22,6))
for i in range(4):
  plt.plot(data.iloc[:,i], 
          label=col[i])
plt.ylabel('Цена.руб')
plt.legend()
plt.show()

#Chanel volume
plt.figure(figsize=(22,6))
plt.bar(x=data.index, height=data.iloc[:,4], label="Volume")
plt.legend()
plt.show()

def split_dataset(data, split_size=0.2):
  test_len = data.shape[0] - int(data.shape[0]*split_size)
  data_test = data.iloc[test_len:]
  data_train_initial = data.iloc[:test_len]
  data_train = data_train_initial.copy(deep=True)
  data_train_down = data_train_initial.copy(deep=True)
  return data_train_initial, data_train, data_train_down, data_test

data_train_initial, data_train, data_train_down, data_test = split_dataset(data)

# Create target to up move
def target(df):
  pd.options.mode.chained_assignment = None
  df['Y'] = 0
  for i in range(1,forward_lag+1):
    column_name_up = 'Y%d'%(i)
    df[column_name_up] = df['<HIGH>'].shift(-i)
    df.loc[((df[column_name_up] - df['<CLOSE>']) / df['<CLOSE>']) >= (0+flat), column_name_up] = 1
    df.loc[df[column_name_up] != 1, column_name_up] = 0
    df.loc[df[column_name_up] != 0, 'Y'] = 1
    del df[column_name_up]
  
  df['Y'] = df['Y'].shift(1)  # It is necessary to apply later keras.timeseries generator
  
  for c in price_columns:
    df[c]=df[c].pct_change()

  df.dropna(axis=0, how = 'any',inplace=True)

  return df

# Create target to down move
def target_down(df):
  pd.options.mode.chained_assignment = None
  df['Y'] = 0
  for i in range(1,forward_lag+1):
    column_name_up = 'Y%d'%(i)
    df[column_name_up] = df['<CLOSE>'].shift(-i)
    df.loc[((df[column_name_up] - df['<CLOSE>']) / df['<CLOSE>']) <= (0-flat/2), column_name_up] = 1
    df.loc[df[column_name_up] != 1, column_name_up] = 0
    df.loc[df[column_name_up] != 0, 'Y'] = 1
    del df[column_name_up]

  df['Y'] = df['Y'].shift(1)  # It is necessary to apply later keras.timeseries generator

  for c in price_columns:
    df[c]=df[c].pct_change()

  df.dropna(axis=0, how = 'any',inplace=True)

  return df

# Apply target functions
data_train = target(data_train)
print(data_train)
data_train_down = target_down(data_train_down)
print(data_train_down)

# Here is the code to check data of stock manualy. Launch only if need to check any new ticker
# Get data of stock
ticker_data = exporter.lookup(market=Market.USA, code='FTNT',
                          name_comparator=LookupComparator.CONTAINS)
assert len(ticker_data) == 1
df = exporter.download(ticker_data.index[0], market=Market.USA, timeframe=Timeframe.HOURLY)
df = df.iloc[:,2:]
df.reset_index(inplace=True, drop=True)

# Draw the data in channels
plt.figure(figsize=(22,6))
for i in range(4):
  plt.plot(df.iloc[:,i], 
          label=col[i])
plt.ylabel('price')
plt.legend()
plt.show()

ticker_data = exporter.lookup(market=Market.USA, code='SNPS',
                              name_comparator=LookupComparator.CONTAINS)
print(ticker_data)

# Extend initial dataset with new tickers
tickers_list = ['CSCO', 'FB', 'ADBE', 'PYPL', 'IBM', 'NOW', 'ACN', 'SQ', 'INTU', 'FIS', 'ZM', 'ADP', 'VMW', 'ADSK', 'GPN', 'WDAY', 'TWLO', 'CRWD']

def extend_initial_dataset(initial_df, initial_df_down, tickers_list):
  for ticker in tickers_list:
    # Get data of stock
    ticker_data = exporter.lookup(market=Market.USA, code=ticker,
                              name_comparator=LookupComparator.CONTAINS)
    assert len(ticker_data) == 1
    df = exporter.download(ticker_data.index[0], market=Market.USA, timeframe=Timeframe.HOURLY)
    df = df.iloc[:,2:]
    df.reset_index(inplace=True, drop=True)

    # Draw the data in channels to check if data is ok
    plt.figure(figsize=(22,6))
    for i in range(4):
      plt.plot(df.iloc[:,i], 
              label=col[i])
    plt.ylabel('price')
    plt.legend()
    plt.show()

    df_up = df.copy()
    df_down = df.copy()

    # Apply target functions
    df_up = target(df_up)
    df_down = target_down(df_down)
    print(ticker, df.shape)
    initial_df = pd.concat([initial_df, df_up])
    initial_df.reset_index(inplace=True, drop=True)
    initial_df_down = pd.concat([initial_df_down, df_down])
    initial_df_down.reset_index(inplace=True, drop=True)
  return initial_df, initial_df_down

data_train, data_train_down = extend_initial_dataset(data_train, data_train_down, tickers_list)
print(data_train)
print(data_train_down)

# Show the % of Y=1
print(data_train[data_train['Y'] ==1]['Y'].count() / data_train.shape[0] * 100)
print(data_train[data_train['Y'] ==1]['Y'].count())
print(data_train_down[data_train_down['Y'] ==1]['Y'].count() / data_train.shape[0] * 100)
print(data_train_down[data_train_down['Y'] ==1]['Y'].count())

# Prepare data
def data_preprocessing(data, train=True):
  '''
  Function for data preprocessing. Calculates pct_change, makes scalling separatelly for price and volumes, saves scalers. 
  Separates dataset xTrain, xTest, yTrain, yTest, yTrain01, yTest01
  return: ndarrays and scaler
  '''
  # Pct_change for price columns
  if not train:
    for c in price_columns:
      data[c]=data[c].pct_change()

  data[volume_column] = data[volume_column] + 1e-5  # Add very small figure to exclude devide by 0
  data[volume_column] = data[volume_column].pct_change()

  data.dropna(axis=0, how='any', inplace=True)

  if not os.path.exists("/content/drive/MyDrive/Colab Notebooks/Dipl/scalers/"):
    os.makedirs("/content/drive/MyDrive/Colab Notebooks/Dipl/scalers/")

  # Create filename for scalers
  price_scaler_filename="/content/drive/MyDrive/Colab Notebooks/Dipl/scalers/price_scaler.save"
  volume_scaler_filename="/content/drive/MyDrive/Colab Notebooks/Dipl/scalers/volume_scaler.save"

  if train:
    data = np.array(data)
    # Split dataset to train and test
    val_len = int(data.shape[0]*0.15)
    test_len = int(data.shape[0]*0.15)
    train_len = data.shape[0] - val_len - test_len
    xTrain, xVal, xTest = data[:train_len,:4], data[train_len + xlen:train_len + xlen + val_len,:4], data[train_len + xlen + val_len + xlen:,:4]
    yTrain01, yVal01, yTest01 = np.reshape(data[:train_len,-1], (-1,1)), np.reshape(data[train_len + xlen:train_len + xlen + val_len,-1], (-1,1)), np.reshape(data[train_len + xlen + val_len + xlen:,-1], (-1,1)) 

    # Make scale
    price_scaler = MinMaxScaler(feature_range=(-1, 1))
    price_scaler.fit(np.reshape(xTrain[:,3], (-1,1)))
    xTrain[:,:4] = price_scaler.transform(xTrain[:,:4])
    xVal[:,:4] = price_scaler.transform(xVal[:,:4])
    xTest[:,:4] = price_scaler.transform(xTest[:,:4])
    # Save scaler
    joblib.dump(price_scaler, price_scaler_filename)
    
    volume_scaler = MinMaxScaler(feature_range=(-1,1))
    # volume_scaler.fit(np.reshape(xTrain[:,4], (-1,1)))
    # xTrain[:,4] = np.reshape(volume_scaler.transform(np.reshape(xTrain[:,4], (-1,1))), (1, -1))
    # xTest[:,4] = np.reshape(volume_scaler.transform(np.reshape(xTest[:,4], (-1,1))), (1,-1))
    joblib.dump(volume_scaler, volume_scaler_filename)
    
    return xTrain, xVal, xTest, yTrain01, yVal01, yTest01, price_scaler, volume_scaler
    
  else:
    data = np.array(data)
    xTest = data[-xlen:,:]
    price_scaler = joblib.load(price_scaler_filename) 
    # volume_scaler = joblib.load(volume_scaler_filename)

    xTest[:,:4] = price_scaler.transform(xTest[:,:4])
    # xTest[:,4] = np.reshape(volume_scaler.transform(np.reshape(xTest[:,4], (-1,1))), (1,-1))
    
    xTest = np.expand_dims(xTest, axis=0)
    return xTest, price_scaler

# Apply data preprocessing
xTrain, xVal, xTest, yTrain01, yVal01, yTest01, price_scaler, volume_scaler = data_preprocessing(data_train, train = True)
xTrain, xVal, xTest, yTrain01_down, yVal01_down, yTest01_down, price_scaler, volume_scaler = data_preprocessing(data_train_down, train = True)
print(xTrain)
print(yTrain01)
print(yTrain01_down)

# To check the right scaling/unscaling
print(data.head())
print('with pct change')
print(data_train.head())
print('xtrain')
print(xTrain[:5,:4])
print('inv trans xtrain')
print(price_scaler.inverse_transform(xTrain[:5,:4]))
# print('inv trans ytrain')
# print(price_scaler.inverse_transform(yTrain[:5]))

# Draw scalled dataset to check
plt.figure(figsize=(22,10))
plt.plot(xTrain[:,0], 'c', label='Open', alpha=0.2)
plt.plot(xTrain[:,1], 'y', label='High', alpha=0.2)
plt.plot(xTrain[:,2], 'b', label='Low', alpha=0.2)
plt.plot(xTrain[:,3], 'g', label='Close', alpha=0.2)
# plt.plot(xTrain[:,4], 'r', label='Volume', alpha=0.2)
plt.legend()
plt.show()

print(yTrain01.shape)
print(yVal01.shape)
print(yTrain01_down.shape)
print(yVal01_down.shape)

# Make time series
train_datagen = TimeseriesGenerator(xTrain, yTrain01, xlen, batch_size=batch_size, shuffle=True)
val_datagen = TimeseriesGenerator(xVal, yVal01, xlen, batch_size=batch_size, shuffle=True)
train_datagen_down = TimeseriesGenerator(xTrain, yTrain01_down, xlen, batch_size=batch_size, shuffle=True)
val_datagen_down = TimeseriesGenerator(xVal, yVal01_down, xlen, batch_size=batch_size, shuffle=True)

# Make generator for test data for up model
datagen = TimeseriesGenerator(xTest, yTest01,
                               length=xlen, sampling_rate=1,
                               batch_size=len(xTest), shuffle=True) #размер batch будет равен длине нашей выборки
x_test = []
y_test = []
for i in datagen:
  x_test.append(i[0])
  y_test.append(i[1])

x_test = np.array(x_test[0])
y_test = np.array(y_test[0])

print(y_test.shape)
print(y_test[y_test > 0.5].shape)

# Make generator for test data for down model
datagen_down = TimeseriesGenerator(xTest, yTest01_down,
                               length=xlen, sampling_rate=1,
                               batch_size=len(xTest), shuffle=True) #размер batch будет равен длине нашей выборки
x_test_down = []
y_test_down = []
for i in datagen:
  x_test_down.append(i[0])
  y_test_down.append(i[1])

x_test_down = np.array(x_test_down[0])
y_test_down = np.array(y_test_down[0])

print(y_test_down.shape)
print(y_test_down[y_test_down > 0.5].shape)

"""# Содание моделей, подбор параметров и тестирование"""

#callback
model_name = f'{file_name}'

reduce_lr = ReduceLROnPlateau(monitor='val_auc', factor=0.5,
                              patience=90, min_lr=0.000001, verbose=1, mode="max" )
early_stop = EarlyStopping(
    monitor='val_auc', min_delta=0, patience=120, verbose=1,
    mode='max', baseline=None, restore_best_weights=True)

checkpoint = ModelCheckpoint(f'/content/drive/MyDrive/Colab Notebooks/Dipl/Models/{model_name}.h5', monitor='val_auc', verbose = 1,
                             save_best_only = True, mode='max')

def on_epoch_end_acc(epoch, logs):
  clear_output(wait=True)
  print('current_val_auc',logs['val_auc'])
  print('current bot_epoch:', it + 1, 'of', bot_epohs)
  print('current bot:', bot_number + 1, 'of', n)
  print('last_bot_accuracy:', val )
  print('last_bot_trade_profit:', trade_profit_list)
  print('last_bot_profit_ratio:', profit_ratio_list)
  print('last_bot_trades:', total_trades_list)

def on_epoch_end_trade_test(epoch, logs):
  clear_output(wait=True)
  print('current_val_auc',logs['val_auc'])
  # best_auc = best_auc.append(logs['val_auc'][-1])
  # print('best_auc:', max(best_auc))

clear = LambdaCallback(on_epoch_end=on_epoch_end_trade_test)

# Function for metrics calculation
def f1_loss_calculation(model, x_test, y_test, threshhold=0.6):
  pred = model.predict(x_test)
  pred = np.array([(1 if i>threshhold else 0) for i in pred])
  real = np.array([(1 if i>0.5 else 0) for i in y_test])
  tn, fp, fn, tp = confusion_matrix(real, pred).ravel()
  f1 = round(f1_score(real, pred),3)
  precision = round(tp / (tp + fp), 3)
  recall = round(tp / (tp + fn), 3)
  specificity = round(tn / (tn + fp), 3)
  return f1, precision, specificity, recall, tn, fp, fn, tp

def plot_history(history):
  plt.plot(history.history['auc'], 
          label='AUC на обучающем наборе')
  plt.plot(history.history['val_auc'], 
          label='AUC на проверочном наборе')
  plt.xlabel('Эпоха обучения')
  plt.ylabel('AUC')
  plt.legend()
  plt.show()

def check_model(model, x, y_real):
  pred = model.predict(x)
  roc_auc = roc_auc_score(y_real, pred)
  fpr, tpr, thresholds = roc_curve(y_real, pred)
  print()
  plt.plot(fpr, tpr,'r-',label = 'AUC: %.3f'%roc_auc)
  plt.plot([0,1],[0,1],'k-',label='random')
  plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect',)
  plt.legend()
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Проверка на тестовой выборке')
  plt.show()

  pred = np.array([(1 if i>0.5 else 0) for i in pred])
  real = np.array([(1 if i>0.5 else 0) for i in y_real])
  print(pred)
  print(real)

  tn, fp, fn, tp = confusion_matrix(real, pred).ravel()
  print('tn:', tn, 'fp:', fp, 'fn:', fn, 'tp:', tp)

  print(classification_report(real, pred))

  cnt_pos=0
  cnt_neg=0
  for i in range(real.shape[0]):
    #print('Predict', pred[i], 'Real',real[i])
    if pred[i] == real[i]:
      cnt_pos +=1
    else:
      cnt_neg+=1

  print()
  print('Positive', cnt_pos, 'Negative',cnt_neg, 'Accuracy {:.2%}'.format(cnt_pos/(cnt_pos+cnt_neg)))
  print()

"""# Тестовый запуск модели на датасете"""

# Function to create model
def create_model():
  inputs = Input(shape=(train_datagen[0][0][0].shape))
  dense = Dense(250, activation='relu')(inputs)
  dense = Dropout(0.2)(dense)
  dense = Flatten()(dense)
  final = Dense(1, activation='sigmoid')(dense)
  model = Model(inputs, final)
  return model

def train_model(model, epochs=1000):
  model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-2),  metrics=[AUC(name="auc")])
  #Запускаем обучение
  history = model.fit(train_datagen, 
                      epochs=epochs,
                      verbose=1, 
                      validation_data=val_datagen,
                      callbacks=[reduce_lr, early_stop, clear],
                      ) 
  return history

# Model for up move
model_name = f'{file_name}'
model = create_model()
#Запускаем обучение
history = train_model(model)
plot_history(history)

check_model(model, x_test, y_test)

# Model for down move
model_name_down = f'{file_name}_down'
model_down = create_model()
history = train_model(model_down)
plot_history(history)

check_model(model_down, x_test_down, y_test_down)

def predTimeseriesGenerator(xTest, step_in_the_past):
  '''
  Функция для преобразования размера входного массива в требуемый для нейросети.
  '''
  xTest = xTest[-step_in_the_past:,:,:4] #формируем х длинной step_in_the_past 
  xTest = np.array(xTest) #Преобразуем в numpy
  
  return xTest

#Функция прогноза
def get_prediction (model, model_down, xPred, yScaler, classification=False):
  '''
  Функция для прогноза данных модели регрессии.
  Если classification=True, возвращает номер класса
  По умолчанию возвращает предсказанное значение
  model - модель
  xPred - входной массив данных
  yScaler - скалер для y
  classification - флаг классификации
  '''
  prediction = model.predict(xPred)  # Get prediction by model
  prediction_down = model_down.predict(xPred)
  if classification:  # If classification
    return prediction, prediction_down  # Return probability of 1
  else:
    prediction = yScaler.inverse_transform(prediction)
    return prediction  # Return predicted figure

def trade(data_enter, model, model_down, step_in_the_past):
  '''
  Функция подготовки входных данных, прогноза цены и определения торгового решения
  '''
  data = data_enter.copy(deep=True)  # Копируем входной датасет, чтобы в нем не было изменений 
  xTest, yScaler = data_preprocessing(data, train=False)  # Делаем предобработку данных в массиве функцией data_preprocessing
  xTest = predTimeseriesGenerator(xTest, step_in_the_past) #формируем вектор со взглядом назад для подачи в сеть
  yPred, yPred_down = get_prediction(model, model_down, xTest, yScaler, classification=True) #делаем прогноз следующей цены закрытия

  yPred = yPred[0][0]
  yPred_down = yPred_down[0][0]

  if yPred >= yPred_down:
    action = 1
  elif yPred < yPred_down:
    action = 2
  else:
    action = 0
  #action = np.random.choice(a=[1,0], size=1, p=[yPred, 1-yPred])

  return action, yPred

def test_model(model, model_down):
  '''
  Function to test model by trading on Test dataset
  return: trade_accuracy, profit_ratio
  '''
  initial_money = 100000 # Стартовый капитал
  money = initial_money 
  shares = 0 # Стартовое количество акций
  dataset = data_train_initial  # Get initial test dataset
  money_history = [money] # Статистика капитала

  last_prediction=[0]
  pos=0  # Current position
  enter_price = 0  
  exit_price = 0
  profit_history=[]
  negative_trades = []
  positive_trades = []
  ticker = 3  # Берем цену из колонки "Close"
  buy_hold_enter = 0
  buy_hold_exit = 0
  buy_hold_result = 0
  buy_hold_shares = 0

  # Проходим по всему тестовому датасету
  for i in tqdm(range(1, data_test.shape[0]+1), position=0):
    df = dataset.append(data_test[:i]).reset_index(drop=True) # Считываем очередное значение из тестового датасета и добавляем в основной датасет
    if i == 1:
      buy_hold_enter = df.iloc[-1][ticker]
      buy_hold_shares += money // df.iloc[-1][ticker]

    action, probability = trade(df, model, model_down, xlen) # Получаем действие, которое будем совершать
    
    # Если это последнее значение тестовой выборки, не торгуем
    if i == data_test.shape[0]:
      buy_hold_exit = df.iloc[-1][ticker]
      buy_hold_result = (buy_hold_exit - buy_hold_enter) * buy_hold_shares

      action = 0  
      if shares != 0:
        money += shares * df.iloc[-1][ticker] # Продаем все акции и увеличиваем капитал на заработанные деньги
        shares = 0 # Количество акцией сбрасываем в 0

    # Если должны покупать и есть деньги хотя бы на одну акцию
    if action == 1 and money > df.iloc[-1][ticker] and shares == 0:
      last_price = df.iloc[-1][ticker]
      shares += money // df.iloc[-1][ticker]  # Покупаем на все имеющиеся деньги акции (покупаем целое количество (не обязательно))
      money = round(money % df.iloc[-1][ticker], 2) # Считаем сколько осталось денег после покупки акций
      enter_price = df.iloc[-1][ticker]

    # Если должны продавать и есть акции и текущая цена ниже входа на 0.5%
    elif action == 2 and shares != 0 : 
      money += round((shares * df.iloc[-1][ticker]), 2) # Продаем все акции и увеличиваем капитал на заработанные деньги
      shares = 0 # Количество акцией сбрасываем в 0
      money_history.append(round(money,2)) # Записываем в статистику капитала текущее значение имеющихся денег
      trade_accuracy = round((money_history[-1] - initial_money), 2)
      exit_price = df.iloc[-1][ticker]
      profit_history.append(exit_price - enter_price)


  positive_trades = [i for i in profit_history if i>0]
  negative_trades = [i for i in profit_history if i<=0]
  total_trades = len(profit_history)
  if total_trades != 0:
    positive_trades_ratio = len(positive_trades) / total_trades
    negative_trades_ratio = len(negative_trades) / total_trades
    if len(positive_trades) == 0:
      max_profit = 0
      mean_profit = 0
    else:
      max_profit = max(positive_trades)
      mean_profit = sum(positive_trades) / len(positive_trades)
    if len(negative_trades) == 0:
      draw_down = 0
      mean_loss = 0
      profit_ratio = 1
    else:
      draw_down = min(negative_trades)
      mean_loss = abs(sum(negative_trades)) / len(negative_trades)
      profit_ratio = round(mean_profit / mean_loss, 2)
    
    print('total_trades', total_trades)
    print('positive_trades_ratio', positive_trades_ratio, 'positive_trades', len(positive_trades))
    print('negative_trades_ratio', negative_trades_ratio, 'negative_trades', len(negative_trades))
    print('draw_down', draw_down)
    print('max_profit', max_profit)
    print('profit_ratio', profit_ratio)
  else:
    draw_down = 0
    profit_ratio = 0
    print('total_trades', 0)
    
  trade_return = round((money_history[-1] - initial_money), 2)

  print('buy_hold_result', buy_hold_result)
  print('buy_hold_result %', buy_hold_result/initial_money * 100)

  plt.plot(money_history)
  plt.show()

  return trade_return, profit_ratio, total_trades  # Возвращаем финальный прирост капитала

test_model(model, model_down)

# model.save(f'/content/drive/MyDrive/Colab Notebooks/Dipl/Models/model_test.h5')
# model_down.save(f'/content/drive/MyDrive/Colab Notebooks/Dipl/Models/model_down_test.h5')

# Загружаем модели
model = load_model('/content/drive/MyDrive/Colab Notebooks/Dipl/Models/model_test.h5')
model_down = load_model('/content/drive/MyDrive/Colab Notebooks/Dipl/Models/model_down_test.h5')

best_auc = []
trade_result = pd.DataFrame(columns=['trade_return', 'profit_ratio', 'total_trades'])
print(trade_result)
for _ in range(100):
  model = create_model()
  train_model(model)
  model_down = create_model()
  train_model(model_down)
  trade_return, profit_ratio, total_trades = test_model(model, model_down)
  trade_result = trade_result.append([{'trade_return': trade_return, 'profit_ratio': profit_ratio, 'total_trades': total_trades}])
  trade_result.to_csv('/content/drive/MyDrive/Colab Notebooks/Dipl/test_results/trade_result.csv')

# 'CSCO', 'FB', 'ADBE', 'PYPL', 'IBM', 'NOW', 'ACN', 'SQ', 'INTU', 'FIS', 'ZM', 'ADP', 'VMW', 'ADSK', 'GPN', 'WDAY', 'TWLO', 'CRWD', 'SNPS', 'FTNT'
# Тест на других тикерах
tickers = ['SNPS', 'FTNT']
for t in tickers:
  data = load_ticker(t)
  data_train_initial, data_train, data_train_down, data_test = split_dataset(data)
  test_model(model, model_down)